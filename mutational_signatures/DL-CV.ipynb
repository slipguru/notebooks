{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import dask_searchcv as dcv\n",
    "from distributed import Executor\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.externals.joblib import Parallel, parallel_backend, \\\n",
    "    register_parallel_backend\n",
    "from distributed.joblib import DistributedBackend\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dalila.parameters_research import tune_parameters\n",
    "from dalila.dictionary_learning import DictionaryLearning\n",
    "from dalila.penalty import L1Penalty\n",
    "from dalila.cv_splitting import MonteCarloBootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from unicodedata import normalize\n",
    "filename = \"/home/veronica/Desktop/UVM/mutation_signatures/datasets/breast_cancer_data.mat\"\n",
    "data = loadmat(filename, appendmat=False)\n",
    "v = data[\"originalGenomes\"]\n",
    "types = data[\"types\"]\n",
    "l = len(types)\n",
    "types_1 = [None] * l\n",
    "for i in range(0, l):\n",
    "    types_1[i] = normalize('NFKD', types[i][0][0]).encode('ascii','ignore')\n",
    "data = v.T\n",
    "types = np.asarray(types_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"weak\" mutations from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = remove_weak_mutations(data, 0.01)\n",
    "X = res[\"mutational_catalogue\"]\n",
    "removed_cols = res[\"removed_cols\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Extract mutational signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each possible number of signatures it extracts the dictionary and the coefficients using Dictionary Learning and finding the best regularisation parameters in the grid using Cross-Validation. It performs the fit procedure in parallel, on the same machine, or distributing the jobs with dask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "ss = MonteCarloBootstrap(n_splits=3, test_size=0.2)\n",
    "for k in range(2,10):\n",
    "    estimator = DictionaryLearning(k=k,\n",
    "                               dict_penalty=L1Penalty(1),\n",
    "                               coeff_penalty=L1Penalty(1),\n",
    "                               dict_normalization=1,\n",
    "                               non_negativity=\"both\")\n",
    "    \n",
    "    params = {'dict_penalty': estimator.dict_penalty.make_grid(0.01,0.1, 5),\n",
    "              'coeff_penalty': estimator.dict_penalty.make_grid(0.001,0.01, 5)}\n",
    "\n",
    "    gscv = GridSearchCV(estimator, params, cv=ss,\n",
    "                         iid=True, refit=True, n_jobs=14,\n",
    "                         verbose=1)\n",
    "\n",
    "    #with parallel_backend('distributed',scheduler_host='10.251.61.227:8786'):\n",
    "    gscv.fit(X)\n",
    "\n",
    "    results.append(gscv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compute and plot BIC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC = []\n",
    "for i in range(len(results)):\n",
    "    estimator = results[i].best_estimator_\n",
    "    BIC.append(- np.log(X.shape[0])*np.log(estimator.k) \n",
    "               + 2.3*np.log(estimator.objective_function_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(5,5))\n",
    "markers_on = [3]\n",
    "ax1.plot(np.arange(2,9), -BICs[0:7], '-rD', markevery=markers_on, label=\"BICs\")\n",
    "ax1.set_xlabel(\"Number of mutational signatures\")\n",
    "ax1.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3)\n",
    "plt.rcParams['axes.facecolor'] = (0.5, 0.294, 0.294, 0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best number given the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C,D = results[3].best_estimator_.decomposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-insert the removed \"weak\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = add_removed_cols(D, removed_cols)\n",
    "D_ordered = ordering_for_types(D, types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the resulting atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(D.shape[0]):\n",
    "    plot_atom(our_D[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = np.zeros_like(C)\n",
    "\n",
    "for sample in range(C.shape[0]):\n",
    "    total = np.sum(C[sample,:])\n",
    "    if(total != 0):\n",
    "        percentages[sample,:] = C[sample, :] / total \n",
    "\n",
    "print(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.zeros(D.shape[0])\n",
    "for atom in range(percentages.shape[1]):\n",
    "    frequencies[atom]= len(np.nonzero(percentages[:,atom])[0])\n",
    "plt.figure()\n",
    "plt.hist(np.arange(D.shape[0]),weights=frequencies, bins=D.shape[0], \n",
    "         orientation=\"horizontal\", alpha=0.5, histtype='bar', ec='black');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
